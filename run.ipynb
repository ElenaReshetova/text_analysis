{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open file for analysis\n",
    "filename = \"./data/app_review_bugs_test.csv\"\n",
    "file = codecs.open(filename,\"r\",\"utf8\")\n",
    "dt = pd.read_csv(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cut out useless fields and rows with ratings less than 4 \n",
    "dt_4 = dt[dt['Rating'] < 4]\n",
    "dt_4_p = dt_4.drop(['Device', \"Device Type\", \"Date\", \"AppName\", \"Language\", \"Index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing punctuation marks to '.' and conversation to lower case\n",
    "before_lemm = list(dt_4_p.Review)\n",
    "separates = u\".,!?;:()[]{}\\n\"\n",
    "separates_for_remove = u'\"\\'$@#%^&*+-=\\|/№'\n",
    "for i in range(len(before_lemm)):\n",
    "    before_lemm[i] = unicode(str(before_lemm[i]), 'utf8')\n",
    "    for j in separates_for_remove:\n",
    "        before_lemm[i] = before_lemm[i].replace(j, u\" \")\n",
    "    for j in separates:\n",
    "        before_lemm[i] = before_lemm[i].replace(j, u\" . \")\n",
    "\n",
    "    before_lemm[i] = before_lemm[i].replace(u\" но \", u\" . \")\n",
    "    before_lemm[i] = before_lemm[i].replace(u\" а \", u\" . \")\n",
    "    before_lemm[i] = before_lemm[i].replace(u\".  что \", u\" . \")\n",
    "    \n",
    "    before_lemm[i] = before_lemm[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open file for lemmatization\n",
    "# w[0] - form\n",
    "# w[1] - lemma\n",
    "\n",
    "# you need to open archive new_dict.rar for this file\n",
    "dict_file_name = \"utils/new_dict.txt\"\n",
    "file_lemm = open(dict_file_name, \"r\")\n",
    "lemm_str = file_lemm.readlines()\n",
    "\n",
    "lemm_arr_form = []\n",
    "lemm_arr_orig = []\n",
    "for string in lemm_str:\n",
    "    string=unicode(str(string), 'utf8')\n",
    "    string=string.replace(\"\\n\", \"\")\n",
    "    w = string.split(\" \")\n",
    "    lemm_arr_form.append(w[0])\n",
    "    lemm_arr_orig.append(w[1])\n",
    "\n",
    "file_lemm.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just binary searching\n",
    "def bin_search(arr, word):\n",
    "   l=0\n",
    "   r=len(arr)\n",
    "   while(r-l > 1):\n",
    "      m = (r + l) // 2\n",
    "      if word < arr[m]:\n",
    "         r=m\n",
    "      else:\n",
    "         l=m\n",
    "   return l if arr[l]==word else -1\n",
    "\n",
    "def correct_text(text, lemm_arr_form, lemm_arr_orig):\n",
    "    new = []\n",
    "    reviews = len(text)\n",
    "    for i in range(reviews):\n",
    "        if type(text[i]) != unicode:\n",
    "            review1 = unicode(str(text[i]), 'utf8')\n",
    "        else:\n",
    "            review1 = unicode(text[i])\n",
    "        words = review1.split(u\" \")\n",
    "        new_words = u\"\"\n",
    "        for w in words:\n",
    "            index = bin_search(lemm_arr_form, w)\n",
    "            if index != -1:\n",
    "                w=lemm_arr_orig[index]\n",
    "            new_words += w + u\" \"\n",
    "        new.append(new_words)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting lemms for words in text\n",
    "after_lemmatisation = correct_text(before_lemm, lemm_arr_form, lemm_arr_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading noisy words \n",
    "filename_noise = \"./utils/noise_words.csv\"\n",
    "file_noise = codecs.open(filename_noise,\"r\",\"utf8\")\n",
    "noise_words = pd.read_csv(file_noise, sep=\" \", names=['idx', 'Freq', 'Word', 'Type'])\n",
    "noise_words = noise_words.drop(['idx', 'Freq', 'Type'], axis=1)\n",
    "file_noise.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "were words = 259167\n",
      "removed = 204208\n"
     ]
    }
   ],
   "source": [
    "# removing noisy words\n",
    "n_first_noise_words = 10000\n",
    "first = noise_words.Word[0:n_first_noise_words]\n",
    "first_list = list(first)\n",
    "\n",
    "#to unicode\n",
    "for i in range(len(first_list)):\n",
    "    if type(first_list[i]) != unicode:\n",
    "        first_list[i] = unicode(str(first_list[i]), 'utf8')\n",
    "first_list.sort()\n",
    "\n",
    "after_noise = []\n",
    "indexes = []\n",
    "\n",
    "removed = 0\n",
    "not_removed = 0\n",
    "for i in range(len(after_lemmatisation)):\n",
    "    words = after_lemmatisation[i].split(u\" \")\n",
    "    new_text = u\"\"\n",
    "    local_indexes = []\n",
    "    for j in range(len(words)):\n",
    "        w = words[j]\n",
    "        if w.find(u\".\")>-1 or w == u\"\":\n",
    "            continue\n",
    "        index = bin_search(first_list, w)\n",
    "        if index == -1:\n",
    "            new_text += w + u\" \"\n",
    "            local_indexes.append(j)\n",
    "            not_removed +=1\n",
    "        else:\n",
    "            removed +=1\n",
    "    after_noise.append(new_text)\n",
    "    indexes.append(local_indexes)\n",
    "\n",
    "print \"were words = \" + str(removed + not_removed)\n",
    "print \"removed = \" + str(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading key words\n",
    "key_words_file = \"./utils/key_words.csv\"\n",
    "file_key = codecs.open(key_words_file,\"r\",\"utf8\")\n",
    "key_words_df = pd.read_csv(file_key, sep=\",\")\n",
    "key_words=list(key_words_df[\"word\"])\n",
    "scores=list(key_words_df[\"score\"])\n",
    "file_key.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egorsmir\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:18: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "# do key words searching\n",
    "size = len(after_lemmatisation)\n",
    "points_for_word = 10\n",
    "results = []\n",
    "\n",
    "# loop by reviews\n",
    "for i in range(size):\n",
    "    lemm = after_lemmatisation[i].split(u\" \")\n",
    "    source = before_lemm[i].split(u\" \")\n",
    "    \n",
    "    # do score calculation for each word\n",
    "    n_words=len(lemm)\n",
    "    scores_for_words=[]\n",
    "    for j in range(n_words):\n",
    "        scores_for_words.append(0)\n",
    "        if j in indexes[i]:\n",
    "            scores_for_words[j] += points_for_word\n",
    "        if lemm[j] in key_words:\n",
    "            idx = key_words.index(lemm[j])\n",
    "            scores_for_words[j] += scores[idx]\n",
    "    prev=0\n",
    "    sentence = []\n",
    "    \n",
    "    # compute score for each sentence\n",
    "    for j in range(n_words):\n",
    "        if lemm[j] == \".\":\n",
    "            score = 0\n",
    "            for k in range(prev,j):\n",
    "                score += scores_for_words[k]\n",
    "            sentence.append([score, prev, j])           \n",
    "            prev = j\n",
    "    if prev < n_words -1:\n",
    "        score = 0\n",
    "        for k in range(prev,n_words):\n",
    "            score += scores_for_words[k]\n",
    "        sentence.append([score, prev, n_words])\n",
    "    \n",
    "    # choose 1 sentense with max score\n",
    "    max = 0\n",
    "    idx = 0\n",
    "    for j in range(len(sentence)):\n",
    "        if sentence[j][0] > max:\n",
    "            max = sentence[j][0]\n",
    "            idx = j\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "    x = sentence[idx][1]\n",
    "    if x !=0:\n",
    "        x +=1\n",
    "    y = sentence[idx][2]\n",
    "    results.append(\" \".join(source[x:y]).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing useless spases \n",
    "for i in range(len(results)):\n",
    "    if len(results[i])>0:\n",
    "        while(results[i][0] == \" \"):\n",
    "            results[i] = results[i][1:]\n",
    "            if len(results[i]) == 0:\n",
    "                break\n",
    "    if len(results[i])>0:\n",
    "        while(results[i][len(results[i])-1] == \" \"):\n",
    "            results[i] = results[i][0:len(results[i])-1]\n",
    "            if len(results[i]) == 0:\n",
    "                break\n",
    "    while results[i].find(\"  \")>-1:\n",
    "        results[i] = results[i].replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "очень долго идёт загрузка\n",
      "кнопка выход из приложения неудобно расположена\n",
      "приложение перестало запускаться зависает на инициализация антивируса\n",
      "куда дели переводы клиентам\n",
      "тормозит при запуске\n",
      "долистывю до 14\n",
      "android 7\n",
      "исчезает в приложении вкладка для ввода кода доступа\n",
      "приложение стало почти бесполезным\n",
      "теперь вечный разрыв с интернетом и все ровно какой аператор и какой телефон\n",
      "не хватает возможности распознавать штрихкод и производить произвольные оплаты\n",
      "не дождешься смс никак\n",
      "обмануто около 20 30 тыс человек\n",
      "после обновления не могу зайти в приложение\n",
      "приложение не доработана\n",
      "незаконные требования\n",
      "постоянно запрашивает 5 ти значный пароль при попытке войти в приложение\n",
      "не может установить защищенное соединение\n",
      "кроме перевода между своими счетами и пополнение своего номера мобильного\n",
      "и ваше приложение его проверялось и тоже не обнаружено вирусов\n"
     ]
    }
   ],
   "source": [
    "# examples of result\n",
    "for i in range(20):\n",
    "    print results[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to file\n",
    "out_file_name = \"results.txt\"\n",
    "file = open(out_file_name, \"w+\")\n",
    "\n",
    "res = dt.copy()\n",
    "\n",
    "ratings = list(res[\"Rating\"])\n",
    "reviews = list(res[\"Review\"])\n",
    "\n",
    "file.write(\"Review,IsBag,KeyWords\\n\")\n",
    "\n",
    "\n",
    "size = len(ratings)\n",
    "idx = 0\n",
    "for i in range(size):\n",
    "    string = str(reviews[i]) + \",\"\n",
    "    if ratings[i]>=4:\n",
    "        string += \"false,\"\n",
    "    else:\n",
    "        string += \"true,\" + results[idx]\n",
    "        idx+=1\n",
    "    file.write(string + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
